{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook for Iterative Filtering on US-Twitter data "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from TTMonitor.preprocess import *\r\n",
    "from TTMonitor.TwitterLDA import TwitterLDA\r\n",
    "import pickle\r\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "import pyLDAvis.gensim\r\n",
    "from nltk.corpus import stopwords\r\n",
    "stopwords.words(\"english\")\r\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\r\n",
    "stop_words = ENGLISH_STOP_WORDS\r\n",
    "from datetime import date\r\n",
    "\r\n",
    "# needed to use the TTMonitor module\r\n",
    "class SkTokenizer():\r\n",
    "    def __init__(self):\r\n",
    "        tfidf = TfidfVectorizer()\r\n",
    "        self.tokenize = tfidf.build_tokenizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# set up month to be analyzed\r\n",
    "month = ['Nov']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# these words will be omitted for topic model fitting \r\n",
    "conf_stopwords = ['amp', '000']\r\n",
    "\r\n",
    "COUNTRY = \"US\"\r\n",
    "NAME =\"nov_conspi_monthly_5_topics\"\r\n",
    "preprocess_params = {\"include_hashtags\": True}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The full dictionary after several rounds of iterative filtering. We just added the words found in every iteration to this list:\r\n",
    "include_keywords = [\r\n",
    "    # (non-conspiracy) COVID related keywords\r\n",
    "    'covid',\r\n",
    "    'covid19',\r\n",
    "    'coronavirus',\r\n",
    "    'covid__19',\r\n",
    "    'covid_19',\r\n",
    "    'pandemic',\r\n",
    "    'covidãƒ¼19',\r\n",
    "    'covd',\r\n",
    "    'sars-cov-2',\r\n",
    "    'wearamask',\r\n",
    "    'quarantine',\r\n",
    "    'stayhome',\r\n",
    "    'coviddays',\r\n",
    "    'cdc',\r\n",
    "    'wuhancoronavirus',\r\n",
    "    'wuhanlockdown',\r\n",
    "    'socialdistancingnow',\r\n",
    "    'panicbuy',\r\n",
    "    '14dayquarantine',\r\n",
    "    'duringmy14dayquarantine',\r\n",
    "    'inmyquarantinesurvivalkit',\r\n",
    "    'coronakindness',\r\n",
    "    'quarantinelife',\r\n",
    "    'stayhomechallenge',\r\n",
    "    'dontbeaspreader',\r\n",
    "    'lockdown',\r\n",
    "    'shelteringinplace',\r\n",
    "    'sheltering',\r\n",
    "    'staysafestayhome',\r\n",
    "    'flattenthecurve',\r\n",
    "    'quarentinelife',\r\n",
    "    'saferathome',\r\n",
    "    'stayathome',\r\n",
    "    'epitwitter',\r\n",
    "\r\n",
    "    # potentially conspiracy related keywords         \r\n",
    "    'thestorm',\r\n",
    "    'fooked',\r\n",
    "    'thegreatawakeningworldwide',\r\n",
    "    'justiceforjay',\r\n",
    "    'msm',\r\n",
    "    'dirtyjoe',\r\n",
    "    'obamagate',\r\n",
    "    'lockthemallup',\r\n",
    "    'pizzagate',\r\n",
    "    'pedogateglobal',\r\n",
    "    'treason',\r\n",
    "    'qanon2020',\r\n",
    "    'antifaterrorists',\r\n",
    "    'russiacollusion',\r\n",
    "    'arrestthemboth',\r\n",
    "    'corruption',\r\n",
    "    'doitqarmy',\r\n",
    "    'fightback',\r\n",
    "    'herdhurdheard',\r\n",
    "    'savethechildren',\r\n",
    "    'darktolight',\r\n",
    "    'nomask',\r\n",
    "    'criticalthinker',\r\n",
    "    'nomasks',\r\n",
    "    'wearethenews',\r\n",
    "    'digitalsoldiers',\r\n",
    "    'scamdemic',\r\n",
    "    'wedonotconsent',\r\n",
    "    'idonotconsent',\r\n",
    "    'epstein',\r\n",
    "    'truthmatters',\r\n",
    "    'fuckbillgates',\r\n",
    "    'wearetherevolution',\r\n",
    "    'conspiracy',\r\n",
    "    'saveourchildren',\r\n",
    "    'stoptheabuse',\r\n",
    "    'greatawakening',\r\n",
    "    'wearethenewsnow',\r\n",
    "    'pedowood',\r\n",
    "    'pedogate',\r\n",
    "    'pedogatisrealwwg1wga',\r\n",
    "    'wwg1wwa',\r\n",
    "    'qanon',\r\n",
    "    'qnn',\r\n",
    "    'whereshunter',\r\n",
    "    'wakeupamerica',\r\n",
    "    'theplantosavetheworld',\r\n",
    "    'deepstatetakedown',\r\n",
    "    'qajf',\r\n",
    "    'justiceiscoming',\r\n",
    "    'thedamisbreaking',\r\n",
    "    'disclosure',\r\n",
    "    'sheepnomore',\r\n",
    "    'savehumanity',\r\n",
    "    'questioneverything',\r\n",
    "    'themaskshavefallen',\r\n",
    "    'bilderberg',\r\n",
    "    'bio-engineered',\r\n",
    "    'plandemic',\r\n",
    "    'indoctornation',\r\n",
    "    'virushoax',\r\n",
    "    'hoax',\r\n",
    "    'fakenews',\r\n",
    "    'fakescience',\r\n",
    "    'scamdemic2020hospitalsarenotfull',\r\n",
    "    'democratscamdemic',\r\n",
    "    'covidhoax',\r\n",
    "    'covid1984',\r\n",
    "    'covidvaccineispoison',\r\n",
    "    'qarmy',\r\n",
    "    'trumprussia',\r\n",
    "    'traitor',\r\n",
    "    'exposebillgates',\r\n",
    "    'arrestbillgates',\r\n",
    "    'arrestfauci',\r\n",
    "    'firefauci',\r\n",
    "    'covidcult',\r\n",
    "    'destroydnc',\r\n",
    "    'voterfraud',\r\n",
    "    'electionfraud',\r\n",
    "    'draintheswamp',\r\n",
    "    'nwo',\r\n",
    "    'newworldorder',\r\n",
    "    'illuminati',\r\n",
    "    'ftsn',\r\n",
    "    'chemtrails',\r\n",
    "    'freemason',\r\n",
    "    'freemasonry',\r\n",
    "    'masonic',\r\n",
    "    'thegreatreset',\r\n",
    "    'flatearth',\r\n",
    "    'earthisflat',\r\n",
    "    'lizardpeople',\r\n",
    "    'covidiot',\r\n",
    "    'covididiot',\r\n",
    "    'coronaswimwewr',\r\n",
    "    'viruscoronavirus',\r\n",
    "    'kungflu',\r\n",
    "    'coronapocalypse',\r\n",
    "    'chinesevirus',\r\n",
    "\r\n",
    "    # added in last round of iteration\r\n",
    "    'alexjones',\r\n",
    "    'infowars',\r\n",
    "    'russiahoax'\r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# The full blacklist dictionary after several rounds of iterative filtering. We just added the words found in every iteration to this list:\r\n",
    "exclude_keywords = [                    \r\n",
    "    'cannabis',\r\n",
    "    'CannabisCommunity',\r\n",
    "    'weed',\r\n",
    "    'orlandoweed',\r\n",
    "    'weedporn',\r\n",
    "    'ubranstreetphotography',\r\n",
    "    'streetphotographer',\r\n",
    "    'photodocumentary',\r\n",
    "    'deliciousness',\r\n",
    "    'cheese',\r\n",
    "    'garlic',\r\n",
    "    'photography',\r\n",
    "    'nfl',\r\n",
    "    'vikings',\r\n",
    "    'football',\r\n",
    "    'beach',\r\n",
    "    'gym',\r\n",
    "    'gyms',\r\n",
    "    'nba',\r\n",
    "    'nbabubble',\r\n",
    "    'nbafinals',\r\n",
    "    'lakers',\r\n",
    "    'championship',\r\n",
    "    'happynewyear',\r\n",
    "    'happynewyear2021',\r\n",
    "    'bye2020',\r\n",
    "    'newyear',\r\n",
    "    'newyearseve',\r\n",
    "    'newyear2021nye2020',\r\n",
    "    'nye',\r\n",
    "    'welcome2021',\r\n",
    "    'music',\r\n",
    "    'rap',\r\n",
    "    'hiphop',\r\n",
    "    'sundayvibes',\r\n",
    "    'trap',\r\n",
    "    'quarantinelife',\r\n",
    "    'influencer',\r\n",
    "    'resistancebands',\r\n",
    "    'fitness',\r\n",
    "    'xboxshare',\r\n",
    "    'gears5',\r\n",
    "    'gridiron',\r\n",
    "    'batman'  \r\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prepare LDA\r\n",
    "tokenizer = SkTokenizer()\r\n",
    "lda_params = {\"stop_words\":stop_words, \"tokenizer\":tokenizer, \"enrich\":True,\r\n",
    "              \"doc_threshold\":10, \"similarity_threshold\":0.8}\r\n",
    "\r\n",
    "fit_params={\"n_topics\":5, \"n_jobs\":31, \"no_below\":5,\r\n",
    "            \"no_above\":0.8,\"passes\":200,\"chunksize\":100}\r\n",
    "\r\n",
    "# stopword set is adjusted and then passed as argument as a frozenset\r\n",
    "stop_words_adjust = set(stop_words)\r\n",
    "stop_words_adjust.update(conf_stopwords)\r\n",
    "\r\n",
    "lda_params['stop_words'] = frozenset(stop_words_adjust)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load data\r\n",
    "data = read_datafiles('../../Twitter_US_11_01_2021/load_in_data') \r\n",
    "# filter data by month\r\n",
    "data = [obs for obs in data if obs['created_at'].split()[1] in month] \r\n",
    "# parse tweets\r\n",
    "data = parse_tweets(data, **preprocess_params)\r\n",
    "\r\n",
    "# apply the filters\r\n",
    "data = filter_tweets(data, include_keywords, include=True)\r\n",
    "data = filter_tweets(data, exclude_keywords, include=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LDA estimation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# using TTMonitor module for LDA estimation\r\n",
    "tlda = TwitterLDA(data, **lda_params)\r\n",
    "tlda.fit(**fit_params)\r\n",
    "topics, scores = tlda.classify_tweets()\r\n",
    "print(tlda.coherence)\r\n",
    "tlda.get_topics()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save the results\r\n",
    "identifier = datetime.now().strftime(\"%y%m%d%H%M\") +\"_\"+NAME+\"_\"+COUNTRY\r\n",
    "gensim_data = {'model': tlda.model, 'dictionary': tlda.doc_id2bigram, 'corpus': tlda.corpus_bi}\r\n",
    "\r\n",
    "pickle.dump(tlda, open(identifier+\"_topics_len_\"+str(len(data))+\".pkl\", \"wb\") )\r\n",
    "pickle.dump(gensim_data, open(identifier+\"_gensim_data.pkl\", \"wb\") )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Vizualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pyLDAvis.enable_notebook()\r\n",
    "m = tlda\r\n",
    "lda = m.model\r\n",
    "dictionary = m.doc_id2bigram\r\n",
    "corpus = m.corpus_bi\r\n",
    "\r\n",
    "p = pyLDAvis.gensim.prepare(lda, corpus, dictionary, mds='mmds', sort_topics=False)\r\n",
    "pyLDAvis.save_html(p, identifier+\".html\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('nlp-fraud': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "5b9f437b41ee5b3d4cbe5dba79c551f4b03488fec6b5a5beb605549c6b94a6fe"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
